# ============================================================
#  GPU Dockerfile for Faster Whisper Live (CUDA 12.8 + PyTorch)
# ============================================================

FROM nvidia/cuda:12.8.1-cudnn-runtime-ubuntu24.04

ARG DEBIAN_FRONTEND=noninteractive

# ------------------------------------------------------------
# Install Python 3.10 + pip + dependencies
# ------------------------------------------------------------
RUN apt update && \
    apt install -y software-properties-common curl git portaudio19-dev && \
    add-apt-repository ppa:deadsnakes/ppa && \
    apt update && \
    apt install -y python3.10 python3.10-distutils && \
    curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10 && \
    ln -sf /usr/bin/python3.10 /usr/bin/python && \
    pip3.10 install --no-cache-dir -U "pip>=24" && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# ------------------------------------------------------------
# Create and set working directory
# ------------------------------------------------------------
WORKDIR /app

# ------------------------------------------------------------
# Install PyTorch with CUDA 12 support
# ------------------------------------------------------------
RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# ------------------------------------------------------------
# Install server dependencies
# ------------------------------------------------------------
COPY requirements/server.txt /app/server.txt
RUN pip install --no-cache-dir -r server.txt && rm server.txt

# ------------------------------------------------------------
# Copy project files
# ------------------------------------------------------------
COPY whisper_live /app/whisper_live
COPY run_server.py /app

# ------------------------------------------------------------
# Set CUDA environment variables
# ------------------------------------------------------------
ENV LD_LIBRARY_PATH="/usr/local/cuda/lib64/stubs:${LD_LIBRARY_PATH}"
ENV PYTHONUNBUFFERED=1

# ------------------------------------------------------------
# Expose server port and start
# ------------------------------------------------------------
EXPOSE 9090
CMD ["python", "run_server.py"]