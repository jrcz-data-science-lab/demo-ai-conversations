services:
  ollama:
    build:
      context: ./app/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./app/ollama:/app
    networks:
      - ai_pipeline_net

  tts:
    build:
      context: ./app/tts
    container_name: tts
    ports:
      - "5001:5000"  # Changed from 5000 to avoid macOS conflict
    volumes:
      - ./app/tts:/usr/src/app
    networks:
      - ai_pipeline_net

  faster_whisper_live:
    build:
      context: ./app/faster-whisper-live
      dockerfile: docker/Dockerfile.cpu
    container_name: faster-whisper-live
    ports:
      - "9090:9090"
    networks:
      - ai_pipeline_net
    environment:
      - PYTHONUNBUFFERED=1

  manager:
    build:
      context: ./app/manager
    container_name: manager
    ports:
      - "8000:8000"
    volumes:
      - ./app/manager:/usr/src/app
    depends_on:
      - ollama
      - tts
      - faster_whisper_live
    networks:
      - ai_pipeline_net
    environment:
      - PYTHONUNBUFFERED=1

networks:
  ai_pipeline_net:
    driver: bridge
